{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa9b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to milvus db\n",
    "\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from pymilvus import MilvusClient\n",
    "import os\n",
    "load_dotenv()\n",
    "MILVUS_URI = os.getenv(\"MILVUS_URI\")\n",
    "MILVUS_TOKEN = os.getenv(\"MILVUS_TOKEN\")\n",
    "MILVUS_COLLECTION_NAME = os.getenv(\"MILVUS_COLLECTION_NAME\")\n",
    "\n",
    "milvus_client = MilvusClient(\n",
    "    uri=MILVUS_URI,\n",
    "    token=MILVUS_TOKEN,\n",
    "    collection_name=MILVUS_COLLECTION_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cdb29fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\") or os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    ")\n",
    "\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"Generate embedding for the given text using Gemini.\"\"\"\n",
    "    return embeddings.embed_query(text)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "class Grade(BaseModel):\n",
    "    binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "class TranslationWithScoreAndExplanation(BaseModel):\n",
    "    translation: str = Field(description=\"The translated text. this should be a single translation not a list of translations , should be the source text\")\n",
    "    score: float = Field(description=\"Score evaluating the translation quality, between 0 and 100.\")\n",
    "    explanation: str = Field(description=\"Explanation of the given score for this translation.\")\n",
    "    \n",
    "class TranslationList(BaseModel):\n",
    "    items: List[TranslationWithScoreAndExplanation]\n",
    "    \n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "structured_llm_grader = llm.with_structured_output(Grade)\n",
    "structured_llm_translation_with_score_and_explanation = llm.with_structured_output(TranslationList)\n",
    "\n",
    "def askgemini(prompt: str,is_boolean:bool ) -> str:\n",
    "    \"\"\"Generate a response from Gemini for a given prompt, using LangChain output parser.\"\"\"\n",
    "    if is_boolean:\n",
    "        score = structured_llm_grader.invoke(prompt)\n",
    "        return score.binary_score==\"yes\"\n",
    "    else:\n",
    "        response = llm.invoke(prompt)\n",
    "    # Use output parser to ensure string output\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8aef3858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data: [[{'id': 'oBHDQm3GxAtuWt323H1Py', 'distance': 0.032786883413791656, 'entity': {'parent_id': 'pdxQiFy5eDWhIYcXDSLF0', 'text': 'དཔེར་ན་མིག་སེར་གྱི་ནད་ཀྱིས་བཏབ་པའི་མིག་ཅན་གྱིས་མེད་བཞིན་དུ་དུང་ལ་གསེར་གྱི་རྣམ་པ་ལྟ་བུར་རིག་པ་དེ་བཞིན་དུ་འཁྲུལ་པའི་བག་ཆགས་ཀྱི་དབང་གིས་མེད་ཀྱང་སེར་པོ་ལ་སོགས་པའི་རྣམ་པ་བདེན་པར་མངོན་པར་འདོད་ཅེའོ། །འདིར་ཡང་འདི་འཁྲུལ་པའི་བག་ཆགས་ལ་རག་ལས་པ་ཡིན་ནོ། །'}}, {'id': 'pJMR7iYHGyjDC7g8ljxoF', 'distance': 0.032258063554763794, 'entity': {'parent_id': 'GUkQ8ICEZsVNPdXMTCACF', 'text': 'དེ་ལ་ལུས་ལ་སྤོས་ཀྱིས་བྱུག་པ་ནི་ལུས་ཀྱི་མདོག་མཛེས་པ་དང་དྲི་ཞིམ་པར་བྱ་བའི་ཆེད་དུ་ཨ་ཀ་རུ་དང་འབུ་སུག་ལ་སོགས་པ་དྲི་ཞིམ་པོའི་རྣམ་པ་ལྡེ་གུ་དང་ཕྱེ་མར་བྱས་ཏེ་ལུས་ལ་བསྐུ་ཞིང་གདགས་པར་མི་བྱའོ། །'}}, {'id': 'n7hDT2xPTov2c1pflf8GT', 'distance': 0.0317460335791111, 'entity': {'parent_id': 'nbV7ntgplwYCOkiZCr4yw', 'text': 'དཔེར་ན་རབ་རིབ་ཅན་གྱི་མིག་སྐྱོན་གྱིས་ཉམས་པས་ཟླ་བ་གཉིས་ལ་སོགས་པ་ཡང་དག་པ་མ་ཡིན་པར་མཐོང་བ་བཞིན་ནོ། །'}}, {'id': 'rDMP7yldz6bL4URbFKulV', 'distance': 0.03125, 'entity': {'parent_id': 'Q57a7KtWUy2Oy2o6DmunU', 'text': 'གཞན་ཡང༌ས་ལུའི་མྱུ་གུ་ནི་རང་དང་རྒྱུད་གཅིག་ཏུ་གཏོགས་པ་ས་ལུའི་ས་བོན་ལས་སྐྱེ་ཡི། རྒྱུད་མི་གཅིག་པ་ནས་ཀྱི་ས་བོན་སོགས་ལས་མི་སྐྱེའོ། །'}}, {'id': '9cZqRegwuGqTSySELoyJi', 'distance': 0.03076923079788685, 'entity': {'parent_id': 'LrRLYgyTcahlCYaSbsm1H', 'text': 'དཔེར་ན་སེམས་ལ་མི་འདོད་བཞིན་དུ་ཡང་མཁྲིས་པ་ལ་སོགས་པའི་ནད་འདི་འབྱུང་བར་འགྱུར་བ་ལྟར་དུ། དཔེ་དེ་བཞིན་དུ་སེམས་ལ་མ་འདོད་བཞིན་དུ་ཡང་ནས་ཡང་དུ་ནན་ཏན་གྱིས་ཉོན་མོངས་པའི་དགྲ་འདི་རང་རྒྱུད་ལ་སྐྱེ་ཞིང་འབྱུང་བར་འགྱུར་བ་ནི་དང་པོ་ནས་ཞེ་སྡང་ལང་བ་མིན་ཀྱང་གློ་བུར་བྱུང་བ་ཡིན་པས་ཁག་མེད་བསམ་དགོས་སོ། །'}}]],{'cost': 16, 'scanned_remote_bytes': 0, 'scanned_total_bytes': 60245643, 'cache_hit_ratio': 1.0}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search a text in milvus\n",
    "\n",
    "from pymilvus import AnnSearchRequest, RRFRanker\n",
    "\n",
    "\n",
    "\n",
    "def search_text(milvus_client: MilvusClient, text: str):\n",
    "    \"\"\"\n",
    "    search a text in milvus\n",
    "    \"\"\"\n",
    "    query_embedding=get_embedding(text)\n",
    "    results = milvus_client.search(\n",
    "    collection_name=MILVUS_COLLECTION_NAME,\n",
    "    data=[query_embedding],\n",
    "    limit=5,\n",
    "    output_fields=[\"text\"],\n",
    "    anns_field=\"dense_vector\"\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def hybrid_search(milvus_client: MilvusClient, text: str):\n",
    "    query_embedding=get_embedding(text)\n",
    "    limit=5\n",
    "    search_param_1 = {\n",
    "        \"data\": [query_embedding],\n",
    "        \"anns_field\": \"dense_vector\",\n",
    "        \"param\": {},\n",
    "        \"limit\": limit,\n",
    "    } \n",
    "    request_1 = AnnSearchRequest(**search_param_1)\n",
    "    \n",
    "    search_param_2 = {\n",
    "        \"data\": [query_embedding],\n",
    "        \"anns_field\": \"dense_vector\",\n",
    "        \"param\": {\"drop_ratio_search\": 0.2},\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    request_2 = AnnSearchRequest(**search_param_2)\n",
    "    \n",
    "    \n",
    "    results = milvus_client.hybrid_search(\n",
    "    collection_name=MILVUS_COLLECTION_NAME,\n",
    "    vector=[query_embedding],\n",
    "    reqs=[request_1,request_2],\n",
    "    ranker=RRFRanker(),\n",
    "    limit=limit,\n",
    "    output_fields=[\"text\",\"parent_id\"]\n",
    ")\n",
    "    return results\n",
    "\n",
    "text_search=\"abstract\"\n",
    "hybrid_search(milvus_client,text_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "386aad79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "text_to_translate = \"བོད་སྐད་དུ། དབུ་མ་ལ་འཇུག་པ་ཞེས་བྱ་བ།\\\\nའཇམ་དཔལ་གཞོན་ནུར་གྱུར་པ་ལ་ཕྱག་འཚལ་ལོ། \\\\nཉན་ཐོས་སངས་རྒྱས་འབྲིང་རྣམས་ཐུབ་དབང་སྐྱེས། །སངས་རྒྱས་བྱང་ཆུབ་སེམས་དཔའ་ལས་འཁྲུངས་ཤིང་། །སྙིང་རྗེའི་སེམས་དང་གཉིས་སུ་མེད་བློ་དང་། །བྱང་ཆུབ་སེམས་ནི་རྒྱལ་སྲས་རྣམས་ཀྱི་རྒྱུ། །\"\n",
    "\n",
    "# Get relevant text from Milvus\n",
    "relevant_results = hybrid_search(milvus_client, text_to_translate)\n",
    "relevant_texts = [hit.entity.get(\"text\", \"\") for hit in relevant_results[0]]\n",
    "\n",
    "# Prepare context for translation (combine relevant texts)\n",
    "context = \"\\n\\n\".join(relevant_texts)\n",
    "\n",
    "# Generate translation using Gemini with context from relevant text\n",
    "def generate_translation_with_context(source_text, context):\n",
    "    prompt = f\"Using the following context, translate the Tibetan text to English.\\n\\n 1.do not include any helping text only response with the translation\\n\\n 2. do not include the context in the translation only translate the text source text\\n\\n Context:\\n {context}\\n source text:\\n {source_text}\\n\\n Translation:\"\n",
    "    response = askgemini(prompt,False)\n",
    "    return response\n",
    "\n",
    "def check_if_context_is_relevant(context,text_to_translate):\n",
    "    prompt = f\"Using the following context, check if the context is related to text in any sense.\\n\\n 1.do not include any helping text only response with the translation\\n\\n 2. do not include the context in the translation only translate the text source text\\n\\n 3. only response with true or false if false then reason why it is not relevant\\n\\n Context:\\n {context}\\n source text:\\n {text_to_translate}\\n\\n Translation:\"\n",
    "    response = askgemini(prompt,True)\n",
    "    return response\n",
    "\n",
    "\n",
    "print(check_if_context_is_relevant(context,text_to_translate))\n",
    "\n",
    "# # Generate translations with and without context\n",
    "translation_with_context = generate_translation_with_context(text_to_translate, context)\n",
    "translation_without_context = generate_translation_with_context(text_to_translate, \"\")\n",
    "\n",
    "# compare the two translations with a score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aab61b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compare_translations(translation_with_context, translation_without_context):\n",
    "    prompt = f\"Compare the following two translations and give a score between 0 and 100.\\n\\n source text:\\n {text_to_translate}\\n\\n Translation with context:\\n {translation_with_context}\\n\\n Translation without context:\\n {translation_without_context}\\n\\n Score:\"\n",
    "    response = structured_llm_translation_with_score_and_explanation.invoke(prompt)\n",
    "    return response\n",
    "\n",
    "translation_compare=compare_translations(translation_with_context.content, translation_without_context.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4b2b98f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Tibetan, it is called \"Entering the Middle Way.\"\n",
      "Homage to Manjushri, the youthful form.\n",
      "The Hearers, Pratyekabuddhas, and the intermediate Buddhas are born from the King of Shakyas.\n",
      "The Buddhas and Bodhisattvas arise from them.\n",
      "The mind of compassion and non-duality,\n",
      "The Bodhicitta is the stream of the sons of the victors.\n",
      "95.0\n",
      "This translation is very accurate and captures the meaning of the original text well. The terminology used is appropriate for the subject matter.\n",
      "\n",
      "\n",
      "\n",
      "In Tibetan, it is called \"Introduction to the Middle Way.\"\n",
      "Homage to Manjushri, the youthful one.\n",
      "Hearers, Pratyekabuddhas, and the middling ones are born from the Sage.\n",
      "Buddhas and Bodhisattvas arise from the mind of enlightenment.\n",
      "The mind of compassion and non-duality, and the mind of enlightenment are the lineage of the sons of the victors.\n",
      "85.0\n",
      "This translation is also good, but it has a few minor inaccuracies. For example, \"Entering the Middle Way\" is a more accurate translation of the title than \"Introduction to the Middle Way.\" Additionally, the explanation of the origin of Buddhas and Bodhisattvas is slightly less clear than in the other translation.\n"
     ]
    }
   ],
   "source": [
    "print(translation_compare.items[0].translation)\n",
    "print(translation_compare.items[0].score)\n",
    "print(translation_compare.items[0].explanation)\n",
    "print('\\n\\n')\n",
    "print(translation_compare.items[1].translation)\n",
    "print(translation_compare.items[1].score)\n",
    "print(translation_compare.items[1].explanation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
